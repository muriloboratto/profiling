{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549339c3",
   "metadata": {},
   "source": [
    "# Performance Analysis Profilling on CPU and GPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1cc8f",
   "metadata": {},
   "source": [
    "Welcome to the webinar _Performance Analysis Profilling on CPU and GPU cores_. In this webinar you will learn several techniques for profilling single CPU and GPU applications with an emphasis on supercomputing environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2465e",
   "metadata": {},
   "source": [
    "## The Coding Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b909c",
   "metadata": {},
   "source": [
    "The first step is display information about the CPU architecture with the command `lscpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8685bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea3b9c",
   "metadata": {},
   "source": [
    "In this node, we can observe that the multi-GPU resources connect with the NUMA nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eecce9",
   "metadata": {},
   "source": [
    "For your work today, you have access to several GPUs in the cloud. Run the following cell to see the GPUs available to you today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0fe5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi topo -m "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65989834",
   "metadata": {},
   "source": [
    "While your work today will be on a single node, all the techniques you learn today, can be used to run your applications across clusters of multi-GPU nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfba876",
   "metadata": {},
   "source": [
    "Let us show the NVLink Status for different GPUs reported from `nvidia-smi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338366d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi nvlink --status -i 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666c4e4",
   "metadata": {},
   "source": [
    "In the end, it gives information about the NUMA memory nodes, with tue `lstopo` command, that is used to show the topology of the system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f054097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!lstopo --of png > airis.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57470e88-3846-4cb2-9bb0-3edad6cbc2b1",
   "metadata": {},
   "source": [
    "This will import and display a _.png_ image in Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb812d0f-7679-4bec-8f0f-aca17b3d9214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "path=\"airis.png\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ce682-4e00-4497-aecf-a9c4d7bb5e16",
   "metadata": {},
   "source": [
    "## Environment Modules on AIRIS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6b8ef-a6b8-40b5-9eb1-b939d63bd381",
   "metadata": {},
   "source": [
    "These modules must be initialized before running the jupyter-notebook:\n",
    "```cpp\n",
    "Currently Loaded Modulefiles:\n",
    "    1) anaconda3/2022.05 \n",
    "    2) cuda/11.6         \n",
    "    3) intel/vtune/2023.2.0 \n",
    "    4) python/3.11.5 \n",
    "    5) intel/compiler-rt/2023.2.1\n",
    "    6) openmpi/4.1.5.3\n",
    "    7) intel/icc \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdef8d4-7b1f-4c55-950e-58b64a2e9f64",
   "metadata": {},
   "source": [
    "## Profilling CPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadbcfa5-07ca-4266-8580-3acd1df804e2",
   "metadata": {},
   "source": [
    "Profilling in supercomputational environments is a form of dynamic program analysis that measures. It is necessary to measure the code points that require the highest computational cost of the application so that we can focus our efforts on parallelizing these sections; in this way, we can work intelligently where the code needs to gain performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0619a06b-4d15-4d22-9886-d5a225e830a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile test_cpucores.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "void func1(void)\n",
    "{    \n",
    "    int n = 1024;  \n",
    "    int i,j,k;\n",
    "\n",
    "    int  *A = (int *) malloc (sizeof(int)*n*n);\n",
    "    int  *B = (int *) malloc (sizeof(int)*n*n);\n",
    "    int  *C = (int *) malloc (sizeof(int)*n*n);\n",
    "\n",
    "    for(i = 0; i < n; i++){\n",
    "      for(j = 0; j < n; j++){\n",
    "        A[i*n+j] = rand()%(10-1)*1;\n",
    "        B[i*n+j] = rand()%(10-1)*1;\n",
    "      }\n",
    "    }\n",
    "\n",
    "    for(i = 0; i < n; i++) \n",
    "     for(j = 0; j < n; j++)\n",
    "       for( k = 0; k < n; k++) \n",
    "        C[i*n+j]+=A[i*n+k]*B[k*n+j]; \n",
    "\n",
    "    return;\n",
    "}\n",
    "\n",
    "void func2(void)\n",
    "{\n",
    "    double h, x, s = 0, result;\n",
    "    int a = 0, b = 1;\n",
    "    int n = 1000000;\n",
    "    \n",
    "    h = (b - a) / n;\n",
    "\n",
    "    for(int i = 0; i < n; i++) \n",
    "    {\n",
    "       x = (a + h * (i + 0.5));\n",
    "       s += 100 * x + sin(2 * x * 3.14159);\n",
    "    }\n",
    "\n",
    "    result = h * s;\n",
    "    \n",
    "    return;\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "    printf(\"Inside main()\\n\");\n",
    "\n",
    "    printf(\"Inside func1()\\n\");\n",
    "    func1();\n",
    "    \n",
    "    printf(\"Inside func2()\\n\");\n",
    "    for(int i = 0; i < 500; i++)\n",
    "      func2();\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d51956e-198a-4b9e-893a-b364813ecf33",
   "metadata": {},
   "source": [
    "### ⊗ GPROF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b437f-a104-492e-bfc4-01382e08816b",
   "metadata": {},
   "source": [
    "`GNU profile` (gprof) will be used,  whose primary function is to analyze and capture times during code execution, generating performance reports on multiprocessor environments. To execute the profilling process, insert the _-pg_ argument in the compilation of our sequential code, run it usually to generate the binary file of the report, and, soon after, display it in a readable way through the command associated with gprof, illustrates up as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7593d2-157e-496b-ae76-eefb81c549b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcc test_cpucores.c -o test_gprof -lm -pg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b495b3-ab3c-4894-a07f-4d28a06d37b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./test_gprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff87a9-476f-445c-9fff-9b6c25049921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gprof -b test_gprof gmon.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232479fe-5e87-427a-9a8d-682bbe81c000",
   "metadata": {},
   "source": [
    "### ⊗ VTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8093c4-69a8-4ee4-8000-511aafd4269d",
   "metadata": {},
   "source": [
    "The `Intel(R) VTune(TM) Profiler` Command Line Tool (vtune) perform the hotspots collection based on user mode sampling on the given target, illustrates up as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83299e4-dbbe-40b7-bdcb-0220a6729bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcc -g test_cpucores.c -o test_vtune -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a4f29-58ae-4103-a1f5-ee9f2a050f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!vtune -collect hotspots -r dir_results ./test_vtune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51465efd-cd66-40d6-b9c1-d9305a13be05",
   "metadata": {},
   "source": [
    "#### Using the gprof2dot to Visualize the Call Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede8e46-1e9e-4a5c-8fa6-3614827fd4eb",
   "metadata": {},
   "source": [
    "- Download\n",
    "\n",
    "  * [Git repository](https://github.com/jrfonseca/gprof2dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce430d6f-f6e9-44c7-a113-0729038ce7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!vtune -report gprof-cc -result-dir dir_results/ -format text -report-output output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29117b-f057-4d18-9f22-9bc3ebd296f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!/home/murilo/gprof2dot/gprof2dot.py -f axe output.txt | dot -Tpng -o output.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505d619-c8c0-4228-9273-01c6f62e8608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "path=\"output.png\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765199d-2a35-45d1-b869-0f34d9fad30b",
   "metadata": {},
   "source": [
    "### ☆ Question:\n",
    "\n",
    "- How make profilling in a MPI code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6903d15-ed4a-4378-a68b-8baff3c2ff5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile mm-mpi.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <sys/time.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "void mms(double *a, int fa, int ca, int lda, double *b, int fb, int cb, int ldb, double *c, int fc, int cc, int ldc) {\n",
    "    int i, j, k;\n",
    "    double s;\n",
    "    for (i = 0; i < fa; i++) \n",
    "        for (j = 0; j < cb; j++) {\n",
    "            s = 0.;\n",
    "            for (k = 0; k < ca; k++)\n",
    "                s += a[i * lda + k] * b[k * ldb + j];\n",
    "            c[i * ldc + j] = s;\n",
    "        }\n",
    "}\n",
    "\n",
    "void mm(double *a, int fa, int ca, int lda, double *b, int fb, int cb, int ldb, double *c, int fc, int cc, int ldc, int nodo, int np) {\n",
    "    int i, j, k;\n",
    "    double s;\n",
    "    if (nodo == 0) {\n",
    "        for (i = 1; i < np; i++)\n",
    "            MPI_Send(&a[i * lda * fa / np], fa / np * ca, MPI_DOUBLE, i, 20, MPI_COMM_WORLD);\n",
    "        MPI_Bcast(b, fb * cb, MPI_DOUBLE, 0, MPI_COMM_WORLD);\n",
    "    } else {\n",
    "        MPI_Recv(a, fa / np * ca, MPI_DOUBLE, 0, 20, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "        MPI_Bcast(b, fb * cb, MPI_DOUBLE, 0, MPI_COMM_WORLD);\n",
    "    }\n",
    "    mms(a, fa / np, ca, lda, b, fb, cb, ldb, c, fc / np, cc, ldc);\n",
    "    if (nodo == 0)\n",
    "        for (i = 1; i < np; i++)\n",
    "            MPI_Recv(&c[i * ldc * fc / np],fc / np * cc, MPI_DOUBLE, i, 30, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "    else\n",
    "        MPI_Send(c, fc / np * cc, MPI_DOUBLE, 0, 30, MPI_COMM_WORLD);\n",
    "}\n",
    "\n",
    "void initialize(double *m, int f, int c, int ld) {\n",
    "  int i, j;\n",
    "\n",
    "  for (i = 0; i < f; i++) {\n",
    "    for (j = 0; j < c; j++) {  \n",
    "      m[i * ld + j] = (double)(i + j);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "void initializealea(double *m, int f, int c, int ld) {\n",
    "  int i, j;\n",
    "\n",
    "  for (i = 0; i < f; i++) {\n",
    "    for (j = 0; j < c; j++) {  \n",
    "      m[i * ld + j] = (double)rand() / RAND_MAX;\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "void escribir(double *m, int f, int c, int ld) {\n",
    "  int i, j;\n",
    "\n",
    "  for (i = 0; i < f; i++) {\n",
    "    for (j = 0; j < c; j++) {  \n",
    "      printf(\"%.4lf \",m[i * ld + j]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "}\n",
    "\n",
    "void comparar(double *m1, int fm1, int cm1, int ldm1, double *m2, int fm2, int cm2, int ldm2)\n",
    "{\n",
    "  int i, j;\n",
    "\n",
    "  for(i = 0; i < fm1; i++)\n",
    "    for(j = 0; j < cm1; j++) {\n",
    "      if(m1[i * ldm1 + j] != m2[i * ldm2 + j]) {\n",
    "        printf(\"Diferencia en %d,%d: %.8lf , %.8lf\\n\", i, j, m1[i * ldm1 + j], m2[i * ldm2 + j]);\n",
    "        return;\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) \n",
    "{\n",
    "  int nodo, np, i, j, fa, fal, ca, lda, fb, cb, ldb, fc, fcl, cc, ldc, N;\n",
    "  int long_name;\n",
    "  double ti, tf;\n",
    "  double *a, *b, *c, *c0;\n",
    "  char    nombre_procesador[MPI_MAX_PROCESSOR_NAME];\n",
    "  MPI_Status estado;\n",
    " \n",
    "  MPI_Init(&argc, &argv);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &np);\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &nodo);\n",
    "  MPI_Get_processor_name(nombre_procesador, &long_name);\n",
    "\n",
    "  if (nodo == 0) {\n",
    "    N = atoi(argv[1]);\n",
    "  }\n",
    "\n",
    "  MPI_Bcast(&N, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "  \n",
    "  fa = ca = lda = fb = cb = ldb = fc = cc = ldc = N;\n",
    "  fal = N / np;\n",
    "  fcl = N / np;\n",
    "  if (nodo == 0) {\n",
    "    a = (double *) malloc(sizeof(double) * fa * ca);\n",
    "    b = (double *) malloc(sizeof(double) * fb * cb);\n",
    "    c = (double *) malloc(sizeof(double) * fc * cc);\n",
    "  } else {\n",
    "    a = (double *) malloc(sizeof(double) * fal * ca);\n",
    "    b = (double *) malloc(sizeof(double) * fb * cb);\n",
    "    c = (double *) malloc(sizeof(double) * fcl * cc);\n",
    "  }\n",
    "  \n",
    "  if (nodo == 0) {\n",
    "    c0 = (double *) malloc(sizeof(double) * fc * cc);\n",
    "    initialize(a, fa, ca, lda);\n",
    "    initialize(b, fb, cb, ldb);\n",
    "\n",
    "    mms(a, fa, ca, lda, b, fb, cb, ldb, c0, fc, cc, ldc);\n",
    "  }\n",
    "\n",
    "  MPI_Barrier(MPI_COMM_WORLD);\n",
    "\n",
    "  ti = MPI_Wtime();\n",
    "\n",
    "  mm(a, fa, ca, lda, b, fb, cb, ldb, c, fc, cc, ldc, nodo, np);\n",
    "\n",
    "  MPI_Barrier(MPI_COMM_WORLD);\n",
    "  tf = MPI_Wtime();\n",
    "  if (nodo == 0) {\n",
    "    printf(\"Proceso %d, %s, Tiempo %.6lf\\n\", nodo, nombre_procesador, tf - ti);\n",
    "    comparar(c, fc, cc, ldc, c0, fc, cc, ldc);\n",
    "  }\n",
    "  \n",
    "  free(a);\n",
    "  free(b);\n",
    "  free(c);\n",
    "  if (nodo == 0)\n",
    "    free(c0);\n",
    "  MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d0ca5-113a-4821-9cc9-18275e14c485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mpicc -g mm-mpi.c -o mm-mpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745741b-40c9-43a2-bed3-371496c65cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mpirun -np 4 vtune -collect hotspots -r results ./mm-mpi 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c008691-09d9-4401-b2cd-178290340205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!vtune -report gprof-cc -result-dir results.login2/ -format text -report-output output-mm-mpi.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd809be9-d20c-4f79-b415-561fdd9e0d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!/home/murilo/gprof2dot/gprof2dot.py -f axe output-mm-mpi.txt | dot -Tpng -o output-mm-mpi.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c6aca-142f-482d-9e37-f0fbf4ec71cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "path=\"output-mm-mpi.png\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e334a-32ce-440e-b4f6-80731e9f2d2e",
   "metadata": {},
   "source": [
    "### ⊗ PERF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a36e77-3cbd-4d7d-b2d7-258656b8981d",
   "metadata": {},
   "source": [
    "The `Perf Tool Perform` (perf) performance analysis using counters, mainly referring to cache memories. A simple matrix multiply in the following can show this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0435e8-5235-4b33-9122-d1f062c1788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mm.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "void initializeMatrix(int *A, int n)\n",
    "{\n",
    "  for(int i=0; i < n; i++)\n",
    "    for(int j=0; j < n; j++)\n",
    "      A[i*n+j] = rand()%(10-1)*1; \n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    " int n = atoi(argv[1]);  \n",
    " int i,j,k;\n",
    "\n",
    " int  *A = (int *) malloc (sizeof(int)*n*n);\n",
    " int  *B = (int *) malloc (sizeof(int)*n*n);\n",
    " int  *C = (int *) malloc (sizeof(int)*n*n);\n",
    "\n",
    " initializeMatrix(A,n);\n",
    " initializeMatrix(B,n);\n",
    "\n",
    " for(i = 0; i < n;  i++)\n",
    "    for(j = 0; j < n; j++) \n",
    "      for(k = 0; k < n;  k++) \n",
    "          C[ i * n + j ] += A[ i * n + k ] * B[ k * n + j ];\n",
    "\n",
    "/*\n",
    " * TODO: Mensure the performance with the loop (j, i, k)\n",
    " */\n",
    "    \n",
    "/*\n",
    " * TODO: Mensure the performance with the loop (i, k, j)\n",
    " */\n",
    "\n",
    " return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e6c8b-55f1-4d33-a524-4ce1ee99eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc mm.c -o mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db34944-f7dd-44bf-8a13-eb9c4c5c984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!perf stat -d ./mm 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae792d-8fb8-40c7-80c3-9b93a2bb8445",
   "metadata": {},
   "source": [
    "After profilling the application with the loop i, j, k, answer the following questions using two new experiments:\n",
    "\n",
    "- Loop (j, i, k);\n",
    "- Loop (i, k, j);\n",
    "\n",
    "and answer the following questions using information displayed in the profilling before:\n",
    "\n",
    "### ☆ Questions:\n",
    "\n",
    "- Were there any differences in code structure in performance? And if so, what would be the justification for this?\n",
    "- How does optimization relate to the concept of memory locality?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46736b8-afe1-47c5-8a54-7263d943350a",
   "metadata": {},
   "source": [
    "## Profilling GPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c083f2-7f08-4fff-85b3-62d567ad9726",
   "metadata": {},
   "source": [
    "The GPU has many units working in parallel, and it is common for it to be bound by different units at different frame sequences. Due to the nature of this behavior, it is beneficial to identify where the GPU cost is going when searching for bottlenecks and to understand what a GPU bottleneck is. Some applications help developers identify bottlenecks, which is useful when optimizing performance, following some NVIDIA profilling tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb8908-8925-4ec2-b1ec-dda31759384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile vector-add.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "\n",
    "void initWith(float num, float *a, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; ++i)\n",
    "    a[i] = num;\n",
    "  \n",
    "}\n",
    "\n",
    "__global__ \n",
    "void addVectorsInto(float *result, float *a, float *b, int N)\n",
    "{\n",
    "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "\n",
    "  for(int i = index; i < N; i += stride)\n",
    "    result[i] = a[i] + b[i];\n",
    "}\n",
    "\n",
    "void checkElementsAre(float target, float *vector, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; i++)\n",
    "  {\n",
    "    if(vector[i] != target)\n",
    "    {\n",
    "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
    "      exit(1);\n",
    "    }\n",
    "  }\n",
    "  printf(\"Success! All values calculated correctly.\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  const int N = 2<<24;\n",
    "  size_t size = N * sizeof(float);\n",
    "\n",
    "  float *a;\n",
    "  float *b;\n",
    "  float *c;\n",
    "\n",
    "  cudaMallocManaged(&a, size);\n",
    "  cudaMallocManaged(&b, size);\n",
    "  cudaMallocManaged(&c, size);\n",
    "\n",
    "  initWith(3, a, N);\n",
    "  initWith(4, b, N);\n",
    "  initWith(0, c, N);\n",
    "\n",
    "  size_t threadsPerBlock;\n",
    "  size_t numberOfBlocks;\n",
    "\n",
    "  int deviceId;\n",
    "  cudaGetDevice(&deviceId);\n",
    "\n",
    "  cudaDeviceProp props;\n",
    "  cudaGetDeviceProperties(&props, deviceId);\n",
    "  int multiProcessorCount = props.multiProcessorCount;\n",
    "  threadsPerBlock = 1024;\n",
    "  numberOfBlocks = 32 * multiProcessorCount;\n",
    "  \n",
    "  cudaError_t addVectorsErr;\n",
    "  cudaError_t asyncErr;\n",
    "\n",
    "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
    "\n",
    "  addVectorsErr = cudaGetLastError();\n",
    "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
    "\n",
    "  asyncErr = cudaDeviceSynchronize();\n",
    "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
    "\n",
    "  checkElementsAre(7, c, N);\n",
    "\n",
    "  cudaFree(a);\n",
    "  cudaFree(b);\n",
    "  cudaFree(c);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca8cda-960b-4784-aa8e-912bfe39dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc vector-add.cu -o vector-add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043007a1-26d5-411c-ae0d-558765f1b77a",
   "metadata": {},
   "source": [
    "### ⊗ NSYS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8d4ad-4689-4c1f-96b2-e80506bb4414",
   "metadata": {},
   "source": [
    "`NVIDIA Nsight Systems` (nsys) is a system-wide performance analysis tool designed to visualize an application’s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04f2bc-fa7e-4322-8409-0e4a91849a36",
   "metadata": {},
   "source": [
    "The command `nsys profile` will generate a `qdrep` report file which can be used in a variety of manners. We use the `--stats=true` flag here to indicate we would like summary statistics printed. There is quite a lot of information printed:\n",
    "\n",
    "- Profile configuration details\n",
    "- Report file(s) generation details\n",
    "- **CUDA API Statistics**\n",
    "- **CUDA Kernel Statistics**\n",
    "- **CUDA Memory Operation Statistics (time and size)**\n",
    "- OS Runtime API Statistics\n",
    "\n",
    "In this lab you will primarily be using the nsys im command line. In the next, you will be using the generated report files to give to the Nsight Systems GUI for visual profilling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac000e9-8814-42db-8872-9c9ed9df52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nsys profile --stats=true ./vector-add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edc4cf-8e83-4e99-865f-796469ff3449",
   "metadata": {},
   "source": [
    "After profilling the application, answer the following questions using information displayed in the `CUDA Kernel Statistics` section of the profilling output.\n",
    "\n",
    "### ☆ Questions:\n",
    "\n",
    "- What was the name of the only CUDA kernel called in this application?\n",
    "- How many times did this kernel run?\n",
    "- How long did it take this kernel to run? Record this time somewhere: you will be optimizing this application and will want to know how much faster you can make it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc374068-9b46-4b39-ada0-bdd04fa09f4d",
   "metadata": {},
   "source": [
    "### ⊗ NCU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7858f4-59bf-4e98-86a7-2791ad193b88",
   "metadata": {},
   "source": [
    "`NVIDIA Nsight Compute` (ncu) provides a non-interactive way to profile applications from the command line. It can print the results directly on the command line or store them in a report file. \n",
    "\n",
    "To print profilling information on the command line on the NCU, do not specify the output file (flag -o). Or, if you want to generate the output file (-o) and still see it on the command line, you can use the --page flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0091a-d8e0-41ad-a6dd-ef1b9bc98341",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncu --set detailed vector-add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e69674-ec46-4574-b4a8-bc626497ef4c",
   "metadata": {},
   "source": [
    "### ☆ Questions:\n",
    "\n",
    "After profilling the application, with ncu, answer the following question:\n",
    "\n",
    "- What was the principal diference between nsys and ncu?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c3d91-9b05-4cd3-a7fc-9af1720ccebf",
   "metadata": {},
   "source": [
    "## Clear the Temporary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a4029-db96-4024-ad00-f734549ec740",
   "metadata": {},
   "source": [
    "Before moving on, please execute the following cell to clear up the directory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1aa56cc-4934-413f-b689-42b82046613b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf dir_results results.login2 mm-mpi* output.png outputLU.png airis.png r000hs gmon.out mm* report1* test_* vector-* ../Documents ../intel *.txt dir_results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8e5be-0bb8-4693-8a9d-96c98b293220",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a305772-febf-4ebf-99cb-e6ad309f5a21",
   "metadata": {},
   "source": [
    "Please continue to the next notebook: [_Visual-Performance-Analysis-Tool_](02-Visual-Performance-Analysis-Tool.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
