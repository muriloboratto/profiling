{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><div align=\"center\">Visual Profiling on GPU Environment</div></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CUDA toolkit ships with the **Nsight Systems**, a powerful GUI application to support the development of accelerated CUDA applications. Nsight Systems generates a graphical timeline of an accelerated application, with detailed information about CUDA API calls, kernel execution, memory activity, ... In this notebook, you will be using the **Nsight Systems** timeline to guide you in optimizing accelerated applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Running Nsight Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this interactive lab environment, we have set up a remote desktop you can access from your browser, where you will be able to launch and use **Nsight Systems**. You will begin by creating a report file for an already-existing vector addition program, after which you will be walked through a series of steps to open this report file in **Nsight Systems**, and to make the visual experience nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Report File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vector-add.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile vector-add.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "void initWith(float num, float *a, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; ++i)\n",
    "    a[i] = num;\n",
    "}\n",
    "\n",
    "__global__\n",
    "void addVectorsInto(float *result, float *a, float *b, int N)\n",
    "{\n",
    "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "\n",
    "  for(int i = index; i < N; i += stride)\n",
    "    result[i] = a[i] + b[i];\n",
    "  \n",
    "}\n",
    "\n",
    "void checkElementsAre(float target, float *vector, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; i++)\n",
    "  {\n",
    "    if(vector[i] != target)\n",
    "    {\n",
    "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
    "      exit(1);\n",
    "    }\n",
    "  }\n",
    "  printf(\"Success! All values calculated correctly.\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int deviceId;\n",
    "  int numberOfSMs;\n",
    "\n",
    "  cudaGetDevice(&deviceId);\n",
    "  cudaDeviceGetAttribute(&numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);\n",
    "\n",
    "  const int N = 2<<24;\n",
    "  size_t size = N * sizeof(float);\n",
    "\n",
    "  float *a;\n",
    "  float *b;\n",
    "  float *c;\n",
    "\n",
    "  cudaMallocManaged(&a, size);\n",
    "  cudaMallocManaged(&b, size);\n",
    "  cudaMallocManaged(&c, size);\n",
    "\n",
    "  initWith(3, a, N);\n",
    "  initWith(4, b, N);\n",
    "  initWith(0, c, N);\n",
    "\n",
    "  size_t threadsPerBlock;\n",
    "  size_t numberOfBlocks;\n",
    "\n",
    "  threadsPerBlock = 256;\n",
    "  numberOfBlocks = 32 * numberOfSMs;\n",
    "\n",
    "  cudaError_t addVectorsErr;\n",
    "  cudaError_t asyncErr;\n",
    "\n",
    "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
    "\n",
    "  addVectorsErr = cudaGetLastError();\n",
    "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
    "\n",
    "  asyncErr = cudaDeviceSynchronize();\n",
    "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
    "\n",
    "  checkElementsAre(7, c, N);\n",
    "\n",
    "  cudaFree(a);\n",
    "  cudaFree(b);\n",
    "  cudaFree(c);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code execution cell directly above to compile and run it. You should see a message printed that indicates it was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvcc vector-add.cu -o vector-add-no-prefetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `nsys profile --stats=true` to create a report file that you will be able to open in the Nsight Systems visual profiler. Here we use the `-o` flag to give the report file a memorable name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! All values calculated correctly.\n",
      "Generating '/tmp/nsys-report-aff2.qdstrm'\n",
      "[1/8] [========================100%] vector-add-no-prefetch-report.nsys-rep\n",
      "[2/8] [========================100%] vector-add-no-prefetch-report.sqlite\n",
      "[3/8] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /home/murilo/profiling/vector-add-no-prefetch-report.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/8] Executing 'osrtsum' stats report\n",
      "\n",
      "Operating System Runtime API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  ---------------------\n",
      "     81,0    1.196.289.173         70  17.089.845,0  10.098.720,0     3.840  100.170.190  26.292.313,0  poll                 \n",
      "      9,0      142.503.296         62   2.298.440,0   2.076.706,0    27.458   21.306.102   3.454.266,0  sem_timedwait        \n",
      "      5,0       82.079.201      1.019      80.548,0      20.723,0     1.014   30.088.663     956.974,0  ioctl                \n",
      "      2,0       34.005.464         34   1.000.160,0       3.888,0     1.266   12.506.352   3.257.714,0  mmap                 \n",
      "      0,0        7.178.710         51     140.759,0       4.044,0     1.304    6.691.387     936.292,0  fopen                \n",
      "      0,0        2.779.427         46      60.422,0       5.745,0     3.211    2.190.315     321.382,0  mmap64               \n",
      "      0,0          899.124          4     224.781,0     145.323,0   111.239      497.238     182.352,0  pthread_create       \n",
      "      0,0          427.076         87       4.908,0       4.540,0     2.103       20.598       2.172,0  open64               \n",
      "      0,0          359.714         11      32.701,0       2.773,0     1.495      121.955      51.982,0  munmap               \n",
      "      0,0          332.856         45       7.396,0       3.742,0     1.950       79.012      12.545,0  fclose               \n",
      "      0,0          120.796          3      40.265,0      57.590,0     1.199       62.007      33.904,0  fcntl                \n",
      "      0,0           95.142          3      31.714,0      11.443,0     7.791       75.908      38.316,0  fread                \n",
      "      0,0           47.800          1      47.800,0      47.800,0    47.800       47.800           0,0  fgets                \n",
      "      0,0           40.335         12       3.361,0       3.387,0     2.594        3.969         453,0  write                \n",
      "      0,0           39.258          6       6.543,0       4.132,0     3.156       14.160       4.644,0  open                 \n",
      "      0,0           21.410         11       1.946,0       1.684,0     1.334        3.699         754,0  read                 \n",
      "      0,0           10.223          4       2.555,0       2.477,0     2.097        3.171         466,0  mprotect             \n",
      "      0,0            8.865          2       4.432,0       4.432,0     2.383        6.482       2.898,0  socket               \n",
      "      0,0            7.947          1       7.947,0       7.947,0     7.947        7.947           0,0  connect              \n",
      "      0,0            5.314          1       5.314,0       5.314,0     5.314        5.314           0,0  pthread_mutex_trylock\n",
      "      0,0            4.462          1       4.462,0       4.462,0     4.462        4.462           0,0  pipe2                \n",
      "      0,0            1.342          1       1.342,0       1.342,0     1.342        1.342           0,0  bind                 \n",
      "\n",
      "[5/8] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  -------------  -------------  -----------  -----------  ------------  ---------------------\n",
      "     53,0      159.609.914          3   53.203.304,0       27.492,0       16.596  159.565.826  92.112.645,0  cudaMallocManaged    \n",
      "     35,0      105.283.859          1  105.283.859,0  105.283.859,0  105.283.859  105.283.859           0,0  cudaDeviceSynchronize\n",
      "     11,0       34.369.076          3   11.456.358,0   11.428.712,0   10.277.598   12.662.766   1.192.824,0  cudaFree             \n",
      "      0,0           72.100          1       72.100,0       72.100,0       72.100       72.100           0,0  cudaLaunchKernel     \n",
      "\n",
      "[6/8] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)                       Name                     \n",
      " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  ----------------------------------------------\n",
      "    100,0      105.281.723          1  105.281.723,0  105.281.723,0  105.281.723  105.281.723          0,0  addVectorsInto(float *, float *, float *, int)\n",
      "\n",
      "[7/8] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count   Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
      " --------  ---------------  ------  --------  --------  --------  --------  -----------  ---------------------------------\n",
      "     85,0       67.834.163  11.385   5.958,0   3.806,0     2.783    89.280      9.802,0  [CUDA Unified Memory memcpy HtoD]\n",
      "     14,0       11.252.799     768  14.652,0   3.967,0     1.823    81.439     22.735,0  [CUDA Unified Memory memcpy DtoH]\n",
      "\n",
      "[8/8] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count   Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
      " ----------  ------  --------  --------  --------  --------  -----------  ---------------------------------\n",
      " 402,653     11.385  0,035     0,004     0,004     1,036     0,119        [CUDA Unified Memory memcpy HtoD]\n",
      " 134,218        768  0,175     0,033     0,004     1,044     0,301        [CUDA Unified Memory memcpy DtoH]\n",
      "\n",
      "Generated:\n",
      "    /home/murilo/profiling/vector-add-no-prefetch-report.nsys-rep\n",
      "    /home/murilo/profiling/vector-add-no-prefetch-report.sqlite\n"
     ]
    }
   ],
   "source": [
    "!nsys profile --stats=true -o vector-add-no-prefetch-report ./vector-add-no-prefetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the Remote Desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, read the instructions that follow in the notebook, and connect with NICE DCV on OGBON:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Connect in login8 on OGBON\n",
    "\n",
    "> ~$ ssh -p 5001 user@ogbon-login8.fieb.org.br \n",
    "\n",
    "#### 2) Create the Alias\n",
    "\n",
    "> ~$ alias dcvCreate=\"dcv create-session profiling\"\n",
    "\n",
    "> ~$ alias dcvList=\"dcv list-sessions\"\n",
    "\n",
    "> ~$ alias dcvClose=\"dcv close-session profiling\"\n",
    "\n",
    "#### 3) Create Session in NICE DCV\n",
    "\n",
    "> ~$ dcvCreate\n",
    "\n",
    "#### 4) Open the browser and connect in the adress associating the alias session\n",
    "\n",
    "    https://ogbon-cgpu4.fieb.org.br:8443#profiling\n",
    "\n",
    "#### 5) Insert the user and password\n",
    "After clicking the _Connect_ button you will be asked for a password, which is registered in the NOC/CS2I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Nsight Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open Nsight Systems, initialize the`nsys-ui` on the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the Report File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open this report file by visiting _File_ -> _Open_ from the Nsight Systems menu and select `vector-add-no-prefetch-report.qdrep`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore Warnings/Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can close and ignore any warnings or errors you see, which are just a result of our particular remote desktop environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make More Room for the Timelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make your experience nicer, full-screen the profiler, close the _Project Explorer_ and hide the *Events View*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the CUDA Unified Memory Timelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, expand the _CUDA_ -> _Unified memory_ and _Context_ timelines, and close the _Threads_ timelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe Many Memory Transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a glance you can see that your application is taking about 1 second to run, and that also, during the time when the `addVectorsInto` kernel is running, that there is a lot of UM memory activity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom into the memory timelines to see more clearly all the small memory transfers being caused by the on-demand memory page faults. A couple tips:\n",
    "\n",
    "1. You can zoom in and out at any point of the timeline by holding `CTRL` while scrolling your mouse/trackpad\n",
    "2. You can zoom into any section by click + dragging a rectangle around it, and then selecting _Zoom in_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparing Code Refactors Iteratively with Nsight Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have **Nsight Systems** up and running and are comfortable moving around the timelines, you will be profiling a series of programs that were iteratively improved using techniques already familiar to you. Each time you profile, information in the timeline will give information supporting how you should next modify your code. Doing this will further increase your understanding of how various CUDA programming techniques affect application performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: What is the Asynchronous Memory Prefetching?\n",
    "\n",
    "The first of all is to understand the meaning of the **asynchronous memory prefetching** technique. A powerful technique to reduce the overhead of page faulting and on-demand memory migrations, both in host-to-device and device-to-host memory transfers, is called **asynchronous memory prefetching**. Using this technique allows programmers to asynchronously migrate unified memory (UM) to any CPU or GPU device in the system, in the background, prior to its use by application code. By doing this, GPU kernels and CPU function performance can be increased on account of reduced page fault and on-demand data migration overhead.\n",
    "\n",
    "Prefetching also tends to migrate data in larger chunks, and therefore fewer trips, than on-demand migration. This makes it an excellent fit when data access needs are known before runtime, and when data access patterns are not sparse.\n",
    "\n",
    "CUDA makes asynchronously prefetching managed memory to either a GPU device or the CPU easy with its `cudaMemPrefetchAsync` function. Here is an example of using it to both prefetch data to the currently active GPU device, and then, to the CPU:\n",
    "\n",
    "```cpp\n",
    "int deviceId;\n",
    "cudaGetDevice(&deviceId);                                         // The ID of the currently active GPU device.\n",
    "\n",
    "cudaMemPrefetchAsync(pointerToSomeUMData, size, deviceId);        // Prefetch to GPU device.\n",
    "cudaMemPrefetchAsync(pointerToSomeUMData, size, cudaCpuDeviceId); // Prefetch to host. `cudaCpuDeviceId` is a\n",
    "                                                                  // built-in CUDA variable.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Compare the Timelines of Prefetching vs. Non-Prefetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactors the vector addition application from above so that the 3 vectors needed by its `addVectorsInto` kernel are asynchronously prefetched to the active GPU device prior to launching the kernel (using [`cudaMemPrefetchAsync`](http://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42)). Open the source code and identify where in the application these changes were made. After reviewing the changes, compile and run the refactored application using the code execution cell directly below. You should see its success message printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vector-add-prefetch-solution.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile vector-add-prefetch-solution.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "void initWith(float num, float *a, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; ++i)\n",
    "    a[i] = num;\n",
    "\n",
    "}\n",
    "\n",
    "__global__\n",
    "void addVectorsInto(float *result, float *a, float *b, int N)\n",
    "{\n",
    "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "\n",
    "  for(int i = index; i < N; i += stride)\n",
    "    result[i] = a[i] + b[i];\n",
    "\n",
    "}\n",
    "\n",
    "void checkElementsAre(float target, float *vector, int N)\n",
    "{\n",
    "  for(int i = 0; i < N; i++)\n",
    "  {\n",
    "    if(vector[i] != target)\n",
    "    {\n",
    "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
    "      exit(1);\n",
    "    }\n",
    "  }\n",
    "  printf(\"Success! All values calculated correctly.\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int deviceId;\n",
    "  int numberOfSMs;\n",
    "\n",
    "  cudaGetDevice(&deviceId);\n",
    "  cudaDeviceGetAttribute(&numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);\n",
    "\n",
    "  const int N = 2<<24;\n",
    "  size_t size = N * sizeof(float);\n",
    "\n",
    "  float *a;\n",
    "  float *b;\n",
    "  float *c;\n",
    "\n",
    "  cudaMallocManaged(&a, size);\n",
    "  cudaMallocManaged(&b, size);\n",
    "  cudaMallocManaged(&c, size);\n",
    "\n",
    "  initWith(3, a, N);\n",
    "  initWith(4, b, N);\n",
    "  initWith(0, c, N);\n",
    "\n",
    "  cudaMemPrefetchAsync(a, size, deviceId);\n",
    "  cudaMemPrefetchAsync(b, size, deviceId);\n",
    "  cudaMemPrefetchAsync(c, size, deviceId);\n",
    "\n",
    "  size_t threadsPerBlock;\n",
    "  size_t numberOfBlocks;\n",
    "\n",
    "  threadsPerBlock = 256;\n",
    "  numberOfBlocks = 32 * numberOfSMs;\n",
    "\n",
    "  cudaError_t addVectorsErr;\n",
    "  cudaError_t asyncErr;\n",
    "\n",
    "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
    "\n",
    "  addVectorsErr = cudaGetLastError();\n",
    "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
    "\n",
    "  asyncErr = cudaDeviceSynchronize();\n",
    "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
    "\n",
    "  checkElementsAre(7, c, N);\n",
    "\n",
    "  cudaFree(a);\n",
    "  cudaFree(b);\n",
    "  cudaFree(c);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc vector-add-prefetch-solution.cu -o vector-add-prefetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a report file for this version of the application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! All values calculated correctly.\n",
      "Generating '/tmp/nsys-report-e685.qdstrm'\n",
      "[1/8] [========================100%] vector-add-prefetch-report.nsys-rep\n",
      "[2/8] [========================100%] vector-add-prefetch-report.sqlite\n",
      "[3/8] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /home/murilo/profiling/vector-add-prefetch-report.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/8] Executing 'osrtsum' stats report\n",
      "\n",
      "Operating System Runtime API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)        Name     \n",
      " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  --------------\n",
      "     77,0    1.037.362.416         65  15.959.421,0  10.152.357,0     3.754  100.214.377  23.710.915,0  poll          \n",
      "      9,0      124.305.808         54   2.301.959,0   2.124.489,0    14.810   21.212.181   3.419.615,0  sem_timedwait \n",
      "      9,0      121.033.061      1.019     118.776,0      19.835,0     1.043   26.444.620   1.155.492,0  ioctl         \n",
      "      3,0       39.557.943         35   1.130.226,0       4.168,0     1.170   13.987.193   3.729.875,0  mmap          \n",
      "      0,0        7.080.911         51     138.841,0       3.966,0     1.346    6.463.934     905.022,0  fopen         \n",
      "      0,0        1.766.263         46      38.397,0       5.458,0     2.952    1.107.787     162.126,0  mmap64        \n",
      "      0,0        1.020.579          5     204.115,0     136.732,0   111.460      466.114     149.754,0  pthread_create\n",
      "      0,0          632.077          3     210.692,0     228.116,0    82.527      321.434     120.402,0  sem_wait      \n",
      "      0,0          426.502         87       4.902,0       4.442,0     1.920       21.313       2.576,0  open64        \n",
      "      0,0          373.902         11      33.991,0       2.672,0     1.166      120.251      54.219,0  munmap        \n",
      "      0,0          282.787         45       6.284,0       3.517,0     1.830       70.599      10.487,0  fclose        \n",
      "      0,0          124.425          3      41.475,0      57.998,0     1.040       65.387      35.212,0  fcntl         \n",
      "      0,0          102.866          3      34.288,0      12.126,0     7.508       83.232      42.449,0  fread         \n",
      "      0,0           45.346         14       3.239,0       2.936,0     1.749        5.433       1.233,0  write         \n",
      "      0,0           42.774          1      42.774,0      42.774,0    42.774       42.774           0,0  fgets         \n",
      "      0,0           30.328          6       5.054,0       4.305,0     2.377        8.291       2.709,0  open          \n",
      "      0,0           18.500         13       1.423,0       1.197,0     1.100        2.949         514,0  read          \n",
      "      0,0           13.039          5       2.607,0       2.138,0     1.909        3.544         819,0  mprotect      \n",
      "      0,0            9.657          2       4.828,0       4.828,0     3.356        6.301       2.082,0  socket        \n",
      "      0,0            9.182          1       9.182,0       9.182,0     9.182        9.182           0,0  connect       \n",
      "      0,0            4.827          1       4.827,0       4.827,0     4.827        4.827           0,0  pipe2         \n",
      "      0,0            1.056          1       1.056,0       1.056,0     1.056        1.056           0,0  bind          \n",
      "\n",
      "[5/8] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)    Max (ns)    StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ------------  ------------  ----------  -----------  ------------  ---------------------\n",
      "     63,0      148.172.279          3  49.390.759,0      42.304,0      17.448  148.112.527  85.495.559,0  cudaMallocManaged    \n",
      "     17,0       39.908.026          3  13.302.675,0  13.140.442,0  12.616.561   14.151.023     779.989,0  cudaFree             \n",
      "     13,0       30.852.987          1  30.852.987,0  30.852.987,0  30.852.987   30.852.987           0,0  cudaDeviceSynchronize\n",
      "      6,0       15.367.578          3   5.122.526,0     448.272,0      11.438   14.907.868   8.477.169,0  cudaMemPrefetchAsync \n",
      "      0,0           62.011          1      62.011,0      62.011,0      62.011       62.011           0,0  cudaLaunchKernel     \n",
      "\n",
      "[6/8] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                       Name                     \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------\n",
      "    100,0          539.485          1  539.485,0  539.485,0   539.485   539.485          0,0  addVectorsInto(float *, float *, float *, int)\n",
      "\n",
      "[7/8] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
      " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ---------------------------------\n",
      "     74,0       33.587.632    192  174.935,0  174.688,0   174.015   185.535      1.133,0  [CUDA Unified Memory memcpy HtoD]\n",
      "     25,0       11.317.829    768   14.736,0    4.031,0     1.919    81.536     22.754,0  [CUDA Unified Memory memcpy DtoH]\n",
      "\n",
      "[8/8] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
      " 402,653       192  2,097     2,097     2,097     2,097     0,000        [CUDA Unified Memory memcpy HtoD]\n",
      " 134,218       768  0,175     0,033     0,004     1,044     0,301        [CUDA Unified Memory memcpy DtoH]\n",
      "\n",
      "Generated:\n",
      "    /home/murilo/profiling/vector-add-prefetch-report.nsys-rep\n",
      "    /home/murilo/profiling/vector-add-prefetch-report.sqlite\n"
     ]
    }
   ],
   "source": [
    "!nsys profile --stats=true -o vector-add-prefetch-report ./vector-add-prefetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the report in Nsight Systems, leaving the previous report open for comparison.\n",
    "\n",
    "### ☆ Questions:\n",
    "\n",
    "- How does the execution time compare to that of the `addVectorsInto` kernel prior to adding asynchronous prefetching?\n",
    "- Locate `cudaMemPrefetchAsync` in the *CUDA API* section of the timeline.\n",
    "- How have the memory transfers changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "At this point in the lab you are able to:\n",
    "\n",
    "- Use the **Nsight Systems** to visually profile the timeline of GPU-accelerated CUDA applications.\n",
    "- Use **Nsight Systems** to identify, and exploit, optimization opportunities in GPU-accelerated CUDA applications.\n",
    "\n",
    "At this point in time you have a wealth of fundamental tools and techniques for accelerating CPU-only applications, and for then optimizing those accelerated applications. In the final, exercise in the next notebook, you will have a chance to apply everything that you've learned to accelerate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear the Temporary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, please execute the following cell to clear up the directory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *vector-add* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please continue to the next notebook: [_Final-Exercise_](03-Final-Exercise.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
